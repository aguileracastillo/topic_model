---
title: "Digitalization and the Organization of Work in the Digital Government Research Library v17.5: A Structural Topic Model"
author: "Andres Aguilera Castillo"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  html_document: default
bibliography: references.bib
---

```{r data, include = FALSE}
library(readr)
library(dplyr)
library(here)
library(naniar)
library(knitr)
# Import DGRL version 17.5 (2021/12/15) 16531 References
# https://faculty.washington.edu/jscholl/dgrl/index.php 
# Master RIS file 
mf_ris <- read.csv(here("data", "DGRL_Lit_Master_v17_ris.csv"))
mf_ris <- as_tibble(mf_ris)
mf_ris <- mf_ris %>%
  replace_with_na_all(condition = ~.x %in% common_na_strings)

## Rename Variables of Interest
mf_ris <- mf_ris %>% rename(type = `Item.Type`, year = `Publication.Year`, author = `Author`, doc_title = `Title`, pub_title = `Publication.Title`, abstract = `Abstract.Note`)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Abstract

Digital Government is a growing and vibrant multidisciplinary field of research, the fast increase in research output has challenged researchers to explore and use novel computational ways and methods to perform evidence synthesis on the extant literature and be able to map a scientific discipline, explore the thematic evolution over time and identify potential avenues for further research. The exploration of the linkages between digitalization and the organization of work remains relatively unexplored in a public sector context. Topic modeling has emerged as a powerful computational technique that contributes to the examination of large amounts of text data. This chapter aims to perform a 'smart literature review' on a subset of the Digital Government Reference Library (DGRL) version 17.5, by using text as data approach and a topic modeling technique known as Latent Dirichlet Allocation (LDA). To our best knowledge, this is the first attempt to use unsupervised machine learning techniques with this data set. This effort may contribute to creating a map of the field, identify the evolving themes in the literature and help to identify promising areas of research.

## Introduction

Recent trends in global scientific output demonstrate a rapid and sustained increase in the production of vast amounts of unstructured data in the form of digitized text. This bounty in research content is challenging researchers to explore and pursue novel methodological approaches and techniques to examine massive volumes of scientific publications. Essentially, the ever-growing amounts of bibliographic information available in almost any field of research exceed human capacity making it necessary to explore computational-assisted approaches for research synthesis. Studies in the history of science have identified a relatively sustained growth pattern in scientific publications over time, this exponential growth rate means a doubling in scientific output every 17 years approximately [@bornmann2021]. This level of growth might be attributed to the increased resources dedicated to the global scientific endeavor and consequently the communication of science via publications. However, it may also be due to what has been dubbed "salami sliced publishing" or the multiple publications of a single research study [@bornmann2007a; @bornmann2015].

Digital Government Research (DGR) as a multidisciplinary research field is experiencing rapid growth in its research output. Contributions to this research domain come from established disciplines such as information science, computer science, organization science, sociology, public administration, and political science [@scholl2021]. The diversity in scope and methods of these disciplines converge in the field of Digital Government enriching it, but at the same time, raising questions as regards the lack of native theoretical developments, thus relying upon frameworks, theories, and conceptualizations from related disciplines [@bannister2015].

The advent of computerization and digitalization has had broad impacts in most aspects of contemporary life, including scientific research. Digitalization has influenced how research is designed and conducted, allowing for the creation and increased availability of ever-growing data sets that require powerful computational methods and enhanced tools to handle abundant information [@meyer2015]. Case in point is unsupervised machine learning techniques for text analysis, this research technology can be used in a wide range of disciplines to examine databases, repositories and corpora thus expanding the methodological repertoire of scholars and opening an opportunity to explore large troves of data.

Research synthesis is part of the literature review process in which the extant scientific knowledge in each academic field is examined to help scholars understand the conceptual structure, themes, and debates to identify trends in the literature and potential areas for further research. This crucial task is labor-intensive, time-consuming, and restricted to a limited number of documents if conducted by traditional "manual" methods [@antons2020a; @asmussen2019]. Still, computer-assisted text analysis does not substitute human intervention, instead it "augments our reading ability" [@grimmer2022], human judgement is deemed necessary for the evaluation and validation of the outcome of these models [@barberá2021].

This chapter explores the contents of The Digital Government Research Library in its version 17.5 (Scholl, 2021a), using a text as data approach and an unsupervised machine learning technique known as Latent Dirichlet Allocation (LDA). According to the DGRL website, version 17.5 of the data set contains 16531 references related to the Digital Government Research (DGR) domain, the most prevalent types of documents are conference papers (33.2%) and journal articles (50%). 

```{r types of documents, echo=FALSE}
by_type <- mf_ris %>% count(`type`) %>% arrange(desc(n))
kable(by_type, col.names = c("Document Type", "Number of Documents"), align = "cc", caption = "Table 1. Contents of DGRL v17.5 without pre-processing")
```

Previous explorations of this reference library using bibliometric and scientometric approaches have revealed the thematic evolution (Alcaide--Muñoz et al., 2017), and identified the most influential journals, conferences and leading scholars in the field (Scholl, 2021b). To our best knowledge this is the first attempt to run a topic model for a corpus in the field of Digital Government Research.

Scholars exploring labor-saving technologies have applied similar techniques expanding the methodological repertoire available and inspiring a similar pursuit for the exploration of the impact of technological change in a public sector context [@arduini2014; @montobbio2022].

RQ

Process

```{r mf_ris, include = FALSE}
summary(mf_ris)
```

# Literature Review // Conceptual framework

You can also embed plots, for example:

## Methods and Data

The Digital Government Research Library version 17.5 is a large curated repository of publications contributing to the field of Digital Government Research (DGR), it contains more than 16500 references among its records. The Library can be downloaded from the website [DGRL](https://faculty.washington.edu/jscholl/dgrl/index.php). The download package contains three types of bibliographic files BibTeX, RIS, and ENL (EndNote). By exploring the BiBTeX, RIS and ENL files, we noticed that the data sets had a large amount of missing data and that some information was available in a file type but not other. For this exercise, the following variables have been deemed of interest for the analysis: type of reference (conference paper or journal article), year of publication, author, document title, publication title and the presence of abstract. Text is a type of unstructured data that requires processing before using it. For replicability purposes, the script for data wrangling, cleaning and processing before running the structural topic model is available in the scripts section of the GitHub repository for this project.

From the initial data wrangling and data cleaning The first criterion for keeping the reference for further analysis was the presence of the Digital Object Identifier (DOI) number, a unique number that was used as the value used to join the data sets and to avoid duplicates.

Abstracts, our main unit of analysis are present in some of the references in the RIS file, year of publication, a key covariate for the structural topic model 

The file formats exploratioThe BIB file
For this analysis, an initial exploration of the files indicated important differences in the 
was downloaded and fields of related metadata, the lion's share being journal articles n=8278 and conference papers n=5493. The unit of analysis for this analysis is the abstract of these two types of documents: conference papers and journal articles.



```{r missing all db, include =FALSE}
miss_all_db <- pct_miss(DGRLv17_5_RIS) %>% round(digits = 2)
```

In its raw and unprocessed form, the data set has a large proportion of missing values `r miss_all_db`%, mostly clustered in metadata not considered relevant for the analysis. Out of the 87 columns just 8 are deemed pertinent and may render some insights. The following visualizations explore the missing values in a subset of the DGRL containing journal articles and conference papers. 

```{r visualization redux 8 var, echo=FALSE, include=TRUE, warning=FALSE, out.width= "80%", fig.cap= "Percentage of missing values in the variables of interest"}
vis_miss(DGRLv17_5_RIS_redux)

```

By visually exploring the contents of the data set, it is evident that a large amount of relevant information is missing. Important covariates for the analysis have a substantial proportion of missing information like year, publication title, also 16.16% of abstracts (our main unit of analysis) is missing. However, the amount of missing data is very different from conference papers and journal articles as seen in the following visualizations.

```{r visualization of journal articles, echo=FALSE, include=TRUE}
articles <- DGRLv17_5_RIS_redux %>% group_by(`type`)%>%
  filter(`type` == "journalArticle")
vis_miss(articles)
```

Almost 50% of the metadata related to the year of publication, a key covariate for this analysis, is missing for the journal articles' subsample. In addition, there is missing a third of the Digital Object Identifier (DOI) information. To solve this problem and not to lose this information deemed relevant, we will describe the use a Zotero add-on [DOI Manager](https://github.com/bwiernik/zotero-shortdoi) to search for the missing information by using the available DOI numbers.

```{r visualization of conference papers, echo=FALSE, include=TRUE}
papers <- DGRLv17_5_RIS_redux %>% group_by(`type`) %>%
  filter(`type` == "conferencePaper")
vis_miss(papers)
```
The conference paper subsample visualization tells a different story, most of the missing information is for the publication title column 73%, followed by the proportion of missing DOI information 64% and 21% of missing information for abstracts.

Zotero Search for Metadata and Retract Watch

The workflow for topic modeling includes text pre-processing meaning data cleaning and data transformation. Some variables of interest are missing and there must be some data preparation before running creating a corpus. In particular, we would like to explore if the covariate year, missing in journal articles could be imputed in a reproducible way by publishing the code used to process the data.

Our main unit of analysis is the abstract of the documents that have the covariates deemed of interest for our exploration. Text is a type of unstructured data, these type of data can be structured for processing using the bag of words approach or the splitting of documents, abstracts in our case, into separate word units or terms and every occurrence of a term is defined as a token. The creation of a bag of words is known as tokenizing. The bag of words approach deliberately ignores the syntax or structure of the text, additional treatment of text include the elimination of punctuation, transform each word to lowercase and in some cases stemming which is a way to reduce a word to its stem or root.

Stemming algorithms: Porter / Snowball / Lancaster

Stop words




## Results

## Discussion

## Conclusions

## References
